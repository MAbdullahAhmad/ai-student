{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perameters\n",
    "\n",
    "- `learning_rate`\n",
    "- `activation`\n",
    "- `loss`\n",
    "- `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Imports\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from collections.abc import Iterable\n",
    "from numbers import Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Customer Exceptions\n",
    "#\n",
    "\n",
    "class InvalidInitialWeights(Exception): pass\n",
    "\n",
    "class UnexpectedInputsShape(Exception): pass\n",
    "class UnexpectedOutputsShape(Exception): pass\n",
    "\n",
    "class InvalidActivation(Exception): pass\n",
    "class InvalidOptimizer(Exception): pass\n",
    "class InvalidLoss(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Sigmoid Activation\n",
    "#\n",
    "\n",
    "class Sigmoid():\n",
    "\n",
    "  def apply(self, x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "  \n",
    "  def apply_derivative(self, x):\n",
    "    sig = self.apply(x)\n",
    "    return sig * (1 - sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Mean Squared Error\n",
    "#\n",
    "\n",
    "class MeanSquaredError():\n",
    "  def calculate(self, y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Stochastic Gradient Descent\n",
    "#\n",
    "\n",
    "class StochasticGradientDescent():\n",
    "  def __init__(self, learning_rate=None):\n",
    "    self.learning_rate = learning_rate\n",
    "\n",
    "  def update(self, model, learning_rate=0.01):\n",
    "    # learning rate\n",
    "    lr = self.learning_rate or model.learning_rate or learning_rate\n",
    "\n",
    "    # hierarchy functions\n",
    "    def update_neuron(neuron, lr): neuron.update(lr)\n",
    "    def update_layer(layer, lr):\n",
    "      for neuron in layer.neurons: update_neuron(neuron, lr)\n",
    "\n",
    "    # if ann\n",
    "    if hasattr(model, 'layers'):\n",
    "      for layer in model.layers: update_layer(layer, lr)\n",
    "    \n",
    "    # if layer\n",
    "    elif hasattr(model, 'neurons'):\n",
    "      for neuron in model.neurons: update_neuron(neuron, lr)\n",
    "    \n",
    "    # if neuron\n",
    "    elif hasattr(model, 'forward'):\n",
    "      update_neuron(model, lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "\n",
    "  # \n",
    "  # Props\n",
    "  # \n",
    "\n",
    "  builtin:dict = {\n",
    "    'activation': {\n",
    "      'default': Sigmoid,\n",
    "      'sigmoid': Sigmoid,\n",
    "    },\n",
    "    'loss': {\n",
    "      'default': MeanSquaredError,\n",
    "      'sigmoid': MeanSquaredError,\n",
    "    },\n",
    "    'optimizer': {\n",
    "      'default': StochasticGradientDescent,\n",
    "      'sgd': StochasticGradientDescent,\n",
    "    }\n",
    "  }\n",
    "\n",
    "  errors:dict = {\n",
    "    'activation': InvalidActivation,\n",
    "    'loss':       InvalidLoss,\n",
    "    'optimizer':  InvalidOptimizer,\n",
    "  }\n",
    "\n",
    "  input:Iterable = []\n",
    "  output:float = 0.0\n",
    "\n",
    "  delta:float = 0.0\n",
    "\n",
    "\n",
    "  weight_gradient:Iterable = []\n",
    "  bias_gradient:float = 0.0\n",
    "\n",
    "\n",
    "\n",
    "  # \n",
    "  # Constructor\n",
    "  # \n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "\n",
    "      input_size:int,\n",
    "      \n",
    "      learning_rate:float=0.1,\n",
    "      activation:str|object='default',\n",
    "      loss:str|object='default',\n",
    "      optimizer:str|object='default',\n",
    "\n",
    "      initial_weights:Number|Iterable=0.1,\n",
    "      initial_bias:Number=0\n",
    "    ):\n",
    "\n",
    "    #> input size and learning rate\n",
    "\n",
    "    # Input Size\n",
    "    self.input_size = input_size\n",
    "    self.input = np.repeat(0, self.input_size)\n",
    "    \n",
    "    # Learning Rate\n",
    "    self.learning_rate = learning_rate\n",
    "\n",
    "    #> activation, loss and optimizer\n",
    "\n",
    "    params = {\n",
    "      'activation': activation,\n",
    "      'loss':       loss,\n",
    "      'optimizer':  optimizer,\n",
    "    }\n",
    "\n",
    "    # iterate all\n",
    "    for idx, target in enumerate(['activation', 'loss', 'optimizer']):\n",
    "\n",
    "      # get param\n",
    "      param = params[target]\n",
    "      \n",
    "      # if object, set directly\n",
    "      if type(param) == object: setattr(self, target, param)\n",
    "\n",
    "      # if present in builtin, set\n",
    "      elif type(param) == str and param in self.builtin[target].keys():\n",
    "        setattr(self, target, self.builtin[target][param]())\n",
    "\n",
    "      # raise error\n",
    "      # if not in {object, str} or string and not in builtin\n",
    "      else: raise self.errors[target](param)\n",
    "\n",
    "\n",
    "    #> Initial Weights & Bias\n",
    "\n",
    "    # initial weights\n",
    "    if isinstance(initial_weights, Number):                                            self.weights = np.repeat(initial_weights, input_size).astype(float)\n",
    "    elif isinstance(initial_weights, Iterable) and len(initial_weights) == input_size: self.weights = np.array(initial_weights).astype(float)\n",
    "    else: raise InvalidInitialWeights(f'Value must be either a number or an Iterable of size {input_size}')\n",
    "\n",
    "    # initialize gradient to zero\n",
    "    self.weight_gradient = np.repeat(0.0, self.input_size)\n",
    "\n",
    "    # initial bias\n",
    "    self.bias = initial_bias\n",
    "\n",
    "\n",
    "  \n",
    "  #\n",
    "  # Forward\n",
    "  #\n",
    "\n",
    "  def forward(self, input):\n",
    "    self.input = np.array(input)\n",
    "\n",
    "    # if 1d, predict\n",
    "    if len(self.input.shape) and self.input.shape[0] == self.input_size:\n",
    "      # weighted sum\n",
    "      weighted_sum = np.dot(self.input, self.weights) + self.bias\n",
    "\n",
    "      # activation\n",
    "      predicted = self.activation.apply(weighted_sum)\n",
    "\n",
    "      # return\n",
    "      return predicted\n",
    "    \n",
    "    # elif 2d, predict multiple\n",
    "    return self.forward_multiple(self.input)\n",
    "\n",
    "\n",
    "\n",
    "  #\n",
    "  # Forward Multiple samples\n",
    "  #\n",
    "\n",
    "  def forward_multiple(self, inputs):\n",
    "    inputs = np.array(inputs)\n",
    "\n",
    "    if len(inputs.shape) < 2 or inputs.shape[1] != self.input_size:\n",
    "      raise UnexpectedInputsShape(f'Inputs shape must be (n, {self.input_size}). found {inputs.shape}')\n",
    "\n",
    "    results = []\n",
    "    for inp in inputs:\n",
    "      results.append(self.forward(inp))\n",
    "\n",
    "    return np.array(results)\n",
    "\n",
    "\n",
    "\n",
    "  #\n",
    "  # Backward Pass (loss & optimize)\n",
    "  #\n",
    "\n",
    "  def backward(self, loss):\n",
    "\n",
    "    # gradient\n",
    "    self.delta = loss * self.activation.apply_derivative(self.output)\n",
    "    \n",
    "    # gradients for weights and bias\n",
    "    self.weight_gradient = self.delta * self.input\n",
    "    self.bias_gradient = self.delta\n",
    "\n",
    "    # return loss for previous neurons\n",
    "    return np.dot(self.delta, self.weights)\n",
    "\n",
    "\n",
    "  def update(self, learning_rate=None):\n",
    "    lr = learning_rate or self.learning_rate\n",
    "    self.weights -= self.weight_gradient\n",
    "    self.bias    -= self.bias_gradient\n",
    "\n",
    "\n",
    "  #\n",
    "  # Train\n",
    "  #\n",
    "\n",
    "  def train(self, inputs:Iterable, outputs:Iterable, epochs:int=100, verbose:int=1):\n",
    "    inputs = np.array(inputs)\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    if len(inputs.shape) < 2 or inputs.shape[1] != self.input_size:    raise UnexpectedInputsShape (f'Inputs shape must be (n, {self.input_size}). found {inputs.shape}')\n",
    "    if len(outputs.shape) != 1 or outputs.shape[0] != inputs.shape[0]: raise UnexpectedOutputsShape(f'Outputs size ({outputs.shape[0]}) differs from no of samples in input ({inputs.shape[0]})')\n",
    "    \n",
    "    for e in range(epochs):\n",
    "      \n",
    "      avg_loss = 0\n",
    "      \n",
    "      for i in range(outputs.shape[0]):\n",
    "\n",
    "        # Forward Pass\n",
    "        predicted = self.forward(inputs[i])\n",
    "\n",
    "        # Loss Calculation\n",
    "        loss = self.loss.calculate(outputs[i], predicted)\n",
    "\n",
    "        # Backward Pass\n",
    "        self.backward(loss)\n",
    "\n",
    "        # Weights Updation\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "        if verbose > 1: print(f'epoch={e+1}, sample={i+1}, loss={loss}')\n",
    "        avg_loss+=loss\n",
    "\n",
    "      avg_loss /= inputs.shape[0]\n",
    "      avg_loss = round(avg_loss, 2)\n",
    "      \n",
    "      if verbose: print(f'epoch={e+1}, avg_loss={avg_loss}')\n",
    "\n",
    "\n",
    "\n",
    "  #\n",
    "  # Test\n",
    "  #\n",
    "\n",
    "  def test(self, inputs:Iterable, outputs:Iterable, verbose:int=0):\n",
    "    inputs = np.array(inputs)\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    if len(inputs.shape) < 2 or inputs.shape[1] != self.input_size:    raise UnexpectedInputsShape (f'Inputs shape must be (n, {self.input_size}). found {inputs.shape}')\n",
    "    if len(outputs.shape) != 1 or outputs.shape[0] != inputs.shape[0]: raise UnexpectedOutputsShape(f'Outputs size ({outputs.shape[0]}) differs from no of samples in input ({inputs.shape[0]})')\n",
    "    \n",
    "\n",
    "    accurate = 0\n",
    "    wrong    = 0\n",
    "    for i in range(inputs.shape[0]):\n",
    "\n",
    "      # Forward Pass\n",
    "      predicted = self.forward(inputs[i])\n",
    "\n",
    "      if predicted == outputs[i]: accurate+=1\n",
    "      else:                       wrong   +=1\n",
    "\n",
    "      if verbose > 1: print(f'sample={i+1}, predicted={predicted}, actual={outputs[i]}, error={outputs[i] - predicted}')\n",
    "\n",
    "    return {\n",
    "      'total':    accurate + wrong,\n",
    "      'accurate': accurate,\n",
    "      'wrong':    wrong,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "from dataset import X, Y\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = Neuron(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, avg_loss=0.46\n",
      "epoch=2, avg_loss=0.5\n",
      "epoch=3, avg_loss=0.5\n",
      "epoch=4, avg_loss=0.5\n",
      "epoch=5, avg_loss=0.5\n",
      "epoch=6, avg_loss=0.5\n",
      "epoch=7, avg_loss=0.5\n",
      "epoch=8, avg_loss=0.5\n",
      "epoch=9, avg_loss=0.5\n",
      "epoch=10, avg_loss=0.5\n",
      "epoch=11, avg_loss=0.5\n",
      "epoch=12, avg_loss=0.5\n",
      "epoch=13, avg_loss=0.5\n",
      "epoch=14, avg_loss=0.5\n",
      "epoch=15, avg_loss=0.5\n",
      "epoch=16, avg_loss=0.5\n",
      "epoch=17, avg_loss=0.5\n",
      "epoch=18, avg_loss=0.5\n",
      "epoch=19, avg_loss=0.5\n",
      "epoch=20, avg_loss=0.5\n",
      "epoch=21, avg_loss=0.5\n",
      "epoch=22, avg_loss=0.5\n",
      "epoch=23, avg_loss=0.5\n",
      "epoch=24, avg_loss=0.5\n",
      "epoch=25, avg_loss=0.5\n",
      "epoch=26, avg_loss=0.5\n",
      "epoch=27, avg_loss=0.5\n",
      "epoch=28, avg_loss=0.5\n",
      "epoch=29, avg_loss=0.5\n",
      "epoch=30, avg_loss=0.5\n",
      "epoch=31, avg_loss=0.5\n",
      "epoch=32, avg_loss=0.5\n",
      "epoch=33, avg_loss=0.5\n",
      "epoch=34, avg_loss=0.5\n",
      "epoch=35, avg_loss=0.5\n",
      "epoch=36, avg_loss=0.5\n",
      "epoch=37, avg_loss=0.5\n",
      "epoch=38, avg_loss=0.5\n",
      "epoch=39, avg_loss=0.5\n",
      "epoch=40, avg_loss=0.5\n",
      "epoch=41, avg_loss=0.5\n",
      "epoch=42, avg_loss=0.5\n",
      "epoch=43, avg_loss=0.5\n",
      "epoch=44, avg_loss=0.5\n",
      "epoch=45, avg_loss=0.5\n",
      "epoch=46, avg_loss=0.5\n",
      "epoch=47, avg_loss=0.5\n",
      "epoch=48, avg_loss=0.5\n",
      "epoch=49, avg_loss=0.5\n",
      "epoch=50, avg_loss=0.5\n",
      "epoch=51, avg_loss=0.5\n",
      "epoch=52, avg_loss=0.5\n",
      "epoch=53, avg_loss=0.5\n",
      "epoch=54, avg_loss=0.5\n",
      "epoch=55, avg_loss=0.5\n",
      "epoch=56, avg_loss=0.5\n",
      "epoch=57, avg_loss=0.5\n",
      "epoch=58, avg_loss=0.5\n",
      "epoch=59, avg_loss=0.5\n",
      "epoch=60, avg_loss=0.5\n",
      "epoch=61, avg_loss=0.5\n",
      "epoch=62, avg_loss=0.5\n",
      "epoch=63, avg_loss=0.5\n",
      "epoch=64, avg_loss=0.5\n",
      "epoch=65, avg_loss=0.5\n",
      "epoch=66, avg_loss=0.5\n",
      "epoch=67, avg_loss=0.5\n",
      "epoch=68, avg_loss=0.5\n",
      "epoch=69, avg_loss=0.5\n",
      "epoch=70, avg_loss=0.5\n",
      "epoch=71, avg_loss=0.5\n",
      "epoch=72, avg_loss=0.5\n",
      "epoch=73, avg_loss=0.5\n",
      "epoch=74, avg_loss=0.5\n",
      "epoch=75, avg_loss=0.5\n",
      "epoch=76, avg_loss=0.5\n",
      "epoch=77, avg_loss=0.5\n",
      "epoch=78, avg_loss=0.5\n",
      "epoch=79, avg_loss=0.5\n",
      "epoch=80, avg_loss=0.5\n",
      "epoch=81, avg_loss=0.5\n",
      "epoch=82, avg_loss=0.5\n",
      "epoch=83, avg_loss=0.5\n",
      "epoch=84, avg_loss=0.5\n",
      "epoch=85, avg_loss=0.5\n",
      "epoch=86, avg_loss=0.5\n",
      "epoch=87, avg_loss=0.5\n",
      "epoch=88, avg_loss=0.5\n",
      "epoch=89, avg_loss=0.5\n",
      "epoch=90, avg_loss=0.5\n",
      "epoch=91, avg_loss=0.5\n",
      "epoch=92, avg_loss=0.5\n",
      "epoch=93, avg_loss=0.5\n",
      "epoch=94, avg_loss=0.5\n",
      "epoch=95, avg_loss=0.5\n",
      "epoch=96, avg_loss=0.5\n",
      "epoch=97, avg_loss=0.5\n",
      "epoch=98, avg_loss=0.5\n",
      "epoch=99, avg_loss=0.5\n",
      "epoch=100, avg_loss=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81845/1000496943.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "neuron.train(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81845/1000496943.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 10, 'accurate': 5, 'wrong': 5}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron.test(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
